{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import load_img, img_to_array\n",
    "\n",
    "target_image_path='img/kot.jpeg'\n",
    "style_reference_image_path='img/star.jpeg'\n",
    "\n",
    "width, height =load_img(target_image_path).size\n",
    "\n",
    "img_height=400\n",
    "img_width=int(width*img_height/height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import vgg19\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img=load_img(image_path,target_size=(img_height, img_width))\n",
    "    img=img_to_array(img)\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    img=vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    x[:,:,0]+=103.939\n",
    "    x[:,:,1]+=116.779\n",
    "    x[:,:,2]+=123.68\n",
    "    x=x[:,:,::-1]\n",
    "    x=np.clip(x,0,255).astype('unit8')\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 3s 0us/step\n",
      "Model został załadowany\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "target_image=K.constant(preprocess_image(target_image_path))\n",
    "style_reference_image=K.constant(preprocess_image(style_reference_image_path))\n",
    "combination_image=K.placeholder((1,img_height,img_width,3))\n",
    "\n",
    "input_tensor=K.concatenate([target_image,\n",
    "                            style_reference_image,\n",
    "                            combination_image], axis=0)\n",
    "\n",
    "model=vgg19.VGG19(input_tensor=input_tensor,\n",
    "                  weights='imagenet',\n",
    "                  include_top=False)\n",
    "print('Model został załadowany')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination-base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x): \n",
    "    features = K.batch_flatten (K.permute_dimensions (x, (2, 0, 1))) \n",
    "    gram=K.dot (features. K.transpose(features)) \n",
    "    return gram\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    S=gram_matrix(style)\n",
    "    C=gram_matrix(combination)\n",
    "    channels=3\n",
    "    size= img_height* img_width\n",
    "    return K.Sum(K.square (S-C)) / (4. * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_loss (x):\n",
    "    a = K.square(\n",
    "         x[:, :img_height -1, img_width- 1, :] -x[:, 1:, :img_width -1, :]) \n",
    "    b = K.square( \n",
    "         x[:, :img_height - 1, img_width -1, :] -x[:, :img_height- 1, 1:, :]) \n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`variable += value` with `tf.Variable`s is not supported. Use `variable.assign_add(value)` to modify the variable, or `out = variable + value` if you need to get a new output Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m target_image_features \u001b[39m=\u001b[39mlayer_features [\u001b[39m0\u001b[39m, :,:,:] \n\u001b[0;32m     16\u001b[0m combination_features\u001b[39m=\u001b[39m layer_features [\u001b[39m2\u001b[39m,:,:,:]\n\u001b[1;32m---> 17\u001b[0m loss \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49mcontent_weight\u001b[39m*\u001b[39;49m content_loss (target_image_features,  combination_features)\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m layer_name \u001b[39min\u001b[39;00m style_layers:\n\u001b[0;32m     20\u001b[0m     layer_features\u001b[39m=\u001b[39m outputs_dict[layer_name]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1519\u001b[0m, in \u001b[0;36mBaseResourceVariable.__iadd__\u001b[1;34m(self, unused_other)\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iadd__\u001b[39m(\u001b[39mself\u001b[39m, unused_other):\n\u001b[1;32m-> 1519\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`variable += value` with `tf.Variable`s is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1520\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39msupported. Use `variable.assign_add(value)` to modify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1521\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mthe variable, or `out = variable + value` if you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1522\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mneed to get a new output Tensor.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: `variable += value` with `tf.Variable`s is not supported. Use `variable.assign_add(value)` to modify the variable, or `out = variable + value` if you need to get a new output Tensor."
     ]
    }
   ],
   "source": [
    "outputs_dict=dict([(layer.name, layer.output) for layer in model.layers])\n",
    "content_layer= \"block5_conv2\"\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "                'block5_conv1']\n",
    "total_variation_weight = 1e-4 \n",
    "style_weight=1. \n",
    "content_weight= 0.025\n",
    "\n",
    "loss=K.variable(0.)\n",
    "\n",
    "layer_features = outputs_dict[content_layer] \n",
    "target_image_features =layer_features [0, :,:,:] \n",
    "combination_features= layer_features [2,:,:,:]\n",
    "loss +=content_weight* content_loss (target_image_features,  combination_features)\n",
    "\n",
    "for layer_name in style_layers:\n",
    "    layer_features= outputs_dict[layer_name]\n",
    "    style_reference_features =layer_features [1,:, :,:]\n",
    "    combination_features= layer_features [2,:, :,:]\n",
    "    sl = style_loss (style_reference_features, combination_features)\n",
    "    loss +=(style_weight / len(style_layers)) * sl\n",
    "loss += total_variation_weight* total_variation_loss (combination_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads= K.gradients (loss, combination_image)[0]\n",
    "\n",
    "fetch_loss_and_grads= K.function([combination_image], [loss, grads])\n",
    "\n",
    "class Evaluator (object):\n",
    "    def _init_(self): \n",
    "        self. loss_value= None \n",
    "        self.grads_values= None\n",
    "    def loss (self, x):\n",
    "        assert self. loss_value is None \n",
    "        x-x.reshape((1, img_height, img_width, 3))\n",
    "        outs =fetch_loss_and_grads ([x])\n",
    "        loss_value =outs[0]\n",
    "        grad_values =outs[1]. flatten().astype('float64')\n",
    "        self.loss_value= loss_value\n",
    "        self.grad_values= grad_values \n",
    "        return self.loss_value\n",
    "    \n",
    "    def grads (self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values =np.copy(self.grad_values)\n",
    "        self.loss_value = None \n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator =Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_1_bfgs_b \n",
    "from scipy.misc import imsave\n",
    "import time\n",
    "\n",
    "result_prefix='style_transfer_result' \n",
    "iterations =20\n",
    "\n",
    "x=preprocess_image (target_image_path)\n",
    "x=x.flatten()\n",
    "\n",
    "for i in range(iterations): \n",
    "    print('Początek iteracji numer', 1) \n",
    "    start_time=time.time()\n",
    "    x, min_val, info =fmin_1_bfgs_b(evaluator. loss, x,\n",
    "                                    fprime=evaluator.grads,\n",
    "                                    maxfun=20)\n",
    "    print('Aktualna wartość straty:', min_val)\n",
    "    img =x.copy().reshape((img_height, img_width, 3))\n",
    "    img= deprocess_image(img)\n",
    "    fname =result_prefix+'_at_iteration_%d.png' %i\n",
    "    imsave(fname, img)\n",
    "    end_time= time.time()\n",
    "    print('Obraz zapisany w pliku. fname')\n",
    "    print('Iteracia numer %d została zakończona w czasie %ds' % (i, end_time-start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
